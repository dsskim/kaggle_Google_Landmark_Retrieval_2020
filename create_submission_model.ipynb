{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Layer, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers, Model\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_MAX_SIZE = 441\n",
    "EMBEDDING_SIZE = 512\n",
    "NUM_TRAIN_LABEL = 81313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3 (Functional)    (None, 12, 12, 2048)      21802784  \n_________________________________________________________________\ngeneralized_mean_pooling2d_3 (None, 2048)              1         \n_________________________________________________________________\nfc (Dense)                   (None, 512)               1049088   \n_________________________________________________________________\nbatchnorm (BatchNormalizatio (None, 512)               2048      \n_________________________________________________________________\nada_cos_3 (AdaCos)           (None, 81313)             41632257  \n=================================================================\nTotal params: 64,486,178\nTrainable params: 64,450,721\nNon-trainable params: 35,457\n_________________________________________________________________\nModel: \"functional_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3_input (InputLay [(None, 441, 441, 3)]     0         \n_________________________________________________________________\ninception_v3 (Functional)    (None, 12, 12, 2048)      21802784  \n_________________________________________________________________\ngeneralized_mean_pooling2d_3 (None, 2048)              1         \n_________________________________________________________________\nfc (Dense)                   (None, 512)               1049088   \n_________________________________________________________________\nbatchnorm (BatchNormalizatio (None, 512)               2048      \n=================================================================\nTotal params: 22,853,921\nTrainable params: 22,818,465\nNon-trainable params: 35,456\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "class Generalized_mean_pooling2D(Layer):\n",
    "    def __init__(self, p=3, epsilon=1e-6, **kwargs):\n",
    "        super(Generalized_mean_pooling2D, self).__init__(**kwargs)\n",
    "\n",
    "        self.init_p = p\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list) or len(input_shape) != 4:\n",
    "            raise ValueError('`GeM` pooling layer only allow 1 input with 4 dimensions(b, h, w, c)')\n",
    "\n",
    "        self.build_shape = input_shape\n",
    "\n",
    "        self.p = self.add_weight(\n",
    "              name='p',\n",
    "              shape=[1,],\n",
    "              initializer=tf.keras.initializers.Constant(value=self.init_p),\n",
    "              regularizer=None,\n",
    "              trainable=True,\n",
    "              dtype=tf.float32\n",
    "              )\n",
    "\n",
    "        self.built=True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = inputs.get_shape()\n",
    "        if isinstance(inputs, list) or len(input_shape) != 4:\n",
    "            raise ValueError('`GeM` pooling layer only allow 1 input with 4 dimensions(b, h, w, c)')\n",
    "\n",
    "        return (tf.reduce_mean(tf.abs(inputs**self.p), axis=[1,2], keepdims=False) + self.epsilon)**(1.0/self.p)\n",
    "    \n",
    "class AdaCos(Layer):\n",
    "    def __init__(self, n_classes=10, regularizer=None, **kwargs):\n",
    "        super(AdaCos, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.regularizer = regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(AdaCos, self).build(input_shape)\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "        self.s = tf.Variable(tf.math.sqrt(2.0)*tf.math.log(self.n_classes - 1.0), trainable=False, aggregation=tf.VariableAggregation.MEAN)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(inputs, axis=1, name='norm_embeddings')\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0, name='norm_loss_weights')\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def get_logits(self, y_true, y_pred):\n",
    "        logits = y_pred\n",
    "\n",
    "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "\n",
    "        B_avg = tf.where(y_true < 1, tf.exp(self.s*logits), tf.zeros_like(logits))\n",
    "        B_avg = tf.reduce_mean(tf.reduce_sum(B_avg, axis=1), name='B_avg')\n",
    "        theta_class = theta[y_true == 1]\n",
    "        theta_med = tfp.stats.percentile(theta_class, q=50)\n",
    "\n",
    "        denominator = tf.cos(tf.minimum(math.pi / 4.0, theta_med))\n",
    "        numerator = tf.math.log(B_avg)\n",
    "        self.s.assign(numerator / denominator)\n",
    "\n",
    "        logits = self.s * logits\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        logits = self.get_logits(y_true, y_pred)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_true, logits)\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        logits = self.get_logits(y_true, y_pred)\n",
    "        accuracy = tf.keras.metrics.categorical_accuracy(y_true, logits)\n",
    "        return accuracy\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.n_classes)\n",
    "\n",
    "backbone = tf.keras.applications.InceptionV3(include_top=False, weights=None, input_shape=[IMAGE_MAX_SIZE, IMAGE_MAX_SIZE, 3], classifier_activation=None)\n",
    "backbone.trainable = True\n",
    "\n",
    "loss_model = AdaCos(NUM_TRAIN_LABEL, regularizer=regularizers.l2(0.01))\n",
    "\n",
    "entire_model = tf.keras.Sequential([\n",
    "    backbone,\n",
    "    Generalized_mean_pooling2D(),\n",
    "    Dense(EMBEDDING_SIZE, name='fc'),\n",
    "    BatchNormalization(name='batchnorm'),\n",
    "    loss_model\n",
    "])\n",
    "entire_model.load_weights(\"./weight/InceptionV3_epoch_6_train_acc_0.478.h5\")\n",
    "\n",
    "feature_extractor = Model(inputs=entire_model.inputs, outputs=entire_model.get_layer('batchnorm').output)\n",
    "entire_model.summary()\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, None, 3], dtype=tf.uint8, name='input_image')\n",
    "    ])\n",
    "    def call(self, input_image):\n",
    "        output_tensors = {}\n",
    "        \n",
    "        # resizing\n",
    "        im = tf.image.resize_with_pad(input_image, 441, 441)\n",
    "        \n",
    "        # preprocessing\n",
    "        im = tf.cast(im, tf.float32)\n",
    "        im = tf.math.divide(im, 255.0)\n",
    "        \n",
    "        extracted_features = self.model(tf.convert_to_tensor([im]))\n",
    "        features = tf.math.l2_normalize(extracted_features[0])\n",
    "        output_tensors['global_descriptor'] = tf.identity(features, name='global_descriptor')\n",
    "        return output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.MyModel object at 0x0000026E4558F580>, because it is not built.\nINFO:tensorflow:Assets written to: ./my_model\\assets\n"
    }
   ],
   "source": [
    "m = MyModel(feature_extractor) #creating our model instance\n",
    "\n",
    "served_function = m.call\n",
    "tf.saved_model.save(\n",
    "      m, export_dir=\"./my_model\", signatures={'serving_default': served_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n��ġ ������ �ƴմϴ�.\n"
    }
   ],
   "source": [
    "!ls ./my_model/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('submission.zip','w') as zip:           \n",
    "    zip.write('./my_model/saved_model.pb', arcname='saved_model.pb') \n",
    "    zip.write('./my_model/variables/variables.data-00000-of-00001', arcname='variables/variables.data-00000-of-00001')\n",
    "    zip.write('./my_model/variables/variables.index', arcname='variables/variables.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "^C\n"
    }
   ],
   "source": [
    "!saved_model_cli show --dir ./my_model/ --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596413987162"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}